{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import fsolve\n",
    "def StockAns (stock: str) -> str :\n",
    "    # Ticker del activo\n",
    "    activo = stock  # Ticker del activo\n",
    "    datos = yf.Ticker(activo).history(period= 'max')\n",
    "\n",
    "    # 2. Calcular los retornos promedio (Average) y la desviación estándar (std)\n",
    "    datos['Average'] = datos[['High', 'Low']].mean(axis=1).pct_change()\n",
    "    datos['std'] = datos['Average'].rolling(window=5).std()\n",
    "\n",
    "    # Eliminar valores NaN para los ajustes\n",
    "    datos.dropna(inplace=True)\n",
    "    \n",
    "    #Función para empezar analisis de datos sobre la acción solicitada\n",
    "    def Model_Po_Ex (stock): \n",
    "    #This function generate the answer to the question \"What is the risk and return of stock x?\"\n",
    "     # 1. Descargar datos históricos del activo\n",
    "        try: \n",
    "            #filtrar datos\n",
    "            datos_filtrados = datos[datos['Average'] > 0]\n",
    "\n",
    "            # --- MODELO POLINOMIAL ---\n",
    "            # Ajustar un modelo polinomial de grado 2\n",
    "            X_poly = np.column_stack((datos['Average'], datos['Average']**2))  # [x, x^2]\n",
    "            X_poly = sm.add_constant(X_poly)  # Añadir intercepto\n",
    "            modelo_poly = sm.OLS(datos['std'], X_poly).fit()\n",
    "\n",
    "            # Coeficientes del modelo polinomial\n",
    "            alpha_poly = modelo_poly.params[0]\n",
    "            beta_1_poly = modelo_poly.params[1]\n",
    "            beta_2_poly = modelo_poly.params[2]\n",
    "\n",
    "            # Predicciones del modelo polinomial\n",
    "            datos['std_pred_poly'] = alpha_poly + beta_1_poly * datos['Average'] + beta_2_poly * datos['Average']**2\n",
    "\n",
    "            # --- MODELO EXPONENCIAL ---\n",
    "            # Definir la función exponencial\n",
    "            def modelo_exponencial(x, alpha, beta):\n",
    "                    return alpha * np.exp(beta * x)\n",
    "            # Ajustar el modelo exponencial\n",
    "            popt, _ = curve_fit(modelo_exponencial, datos['Average'], datos['std'], maxfev=10000)\n",
    "            alpha_exp, beta_exp = popt\n",
    "\n",
    "            # Predicciones del modelo exponencial\n",
    "            datos['std_pred_exp'] = modelo_exponencial(datos['Average'], alpha_exp, beta_exp)\n",
    "\n",
    "            # Crear un diccionario con los datos\n",
    "            data1 = { 'Average': datos['Average'].tolist(), \n",
    "                    'std_pred_poly': datos['std_pred_poly'].tolist(), \n",
    "                    'std_pred_exp': datos['std_pred_exp'].tolist()}\n",
    "\n",
    "            # Función para encontrar la intersección entre dos funciones\n",
    "            def interseccion(x):\n",
    "                std_poly = alpha_poly + beta_1_poly * x + beta_2_poly * x**2\n",
    "                std_exp = alpha_exp * np.exp(beta_exp * x)\n",
    "                return std_poly - std_exp\n",
    "\n",
    "            # Valores iniciales para buscar las raíces\n",
    "            valores_iniciales = [-0.05, 0.05]  # Suponiendo dos intersecciones\n",
    "\n",
    "            # Resolver las raíces\n",
    "            intersecciones = [fsolve(interseccion, x0)[0] for x0 in valores_iniciales]\n",
    "\n",
    "            # Calcular las desviaciones estándar en las intersecciones\n",
    "            resultados = [(x, alpha_poly + beta_1_poly * x + beta_2_poly * x**2) for x in intersecciones]\n",
    "\n",
    "            # Mostrar los resultados\n",
    "            Intersección = {}\n",
    "            for i, (x, y) in enumerate(resultados):\n",
    "                Intersección = {'Average': f\"{x:.4f}\", 'Risk': f\"{y:.4f}\"}\n",
    "                # Crear un diccionario con las intersecciones\n",
    "                intersecciones_dict = {\n",
    "                    'Average': [x for x, y in resultados],\n",
    "                    'Risk': [y for x, y in resultados]\n",
    "                    }\n",
    "            return intersecciones_dict\n",
    "        except ValueError as e:\n",
    "            return \"Error en la ejecución de la función\" + str(e)\n",
    "\n",
    "    def Model_Po_Ex_2(stock):\n",
    "        try:\n",
    "            # --- MODELO POLINOMIAL ---\n",
    "            # Ajustar un modelo polinomial de grado 2\n",
    "            X_poly = np.column_stack((datos['Average'], datos['Average']**2))  # [x, x^2]\n",
    "            X_poly = sm.add_constant(X_poly)  # Añadir intercepto\n",
    "            modelo_poly = sm.OLS(datos['std'], X_poly).fit()\n",
    "\n",
    "            # Coeficientes del modelo polinomial\n",
    "            alpha_poly = modelo_poly.params[0]\n",
    "            beta_1_poly = modelo_poly.params[1]\n",
    "            beta_2_poly = modelo_poly.params[2]\n",
    "\n",
    "            # Predicciones del modelo polinomial\n",
    "            datos['std_pred_poly'] = alpha_poly + beta_1_poly * datos['Average'] + beta_2_poly * datos['Average']**2\n",
    "\n",
    "            # --- MODELO EXPONENCIAL DE GRADO 2 ---\n",
    "            # Definir la función exponencial de grado 2\n",
    "            def modelo_exponencial_grado2(x, alpha, beta1, beta2):\n",
    "                return alpha * np.exp(beta1 * x + beta2 * x**2)\n",
    "\n",
    "            # Ajustar el modelo exponencial de grado 2\n",
    "            popt, _ = curve_fit(modelo_exponencial_grado2, datos['Average'], datos['std'], maxfev=10000)\n",
    "            alpha_exp2, beta1_exp2, beta2_exp2 = popt\n",
    "\n",
    "            # Predicciones del modelo exponencial de grado 2\n",
    "            datos['std_pred_exp2'] = modelo_exponencial_grado2(datos['Average'], alpha_exp2, beta1_exp2, beta2_exp2)\n",
    "\n",
    "            # Función para encontrar la intersección entre dos funciones\n",
    "            def interseccion(x):\n",
    "                std_poly = alpha_poly + beta_1_poly * x + beta_2_poly * x**2\n",
    "                std_exp2 = alpha_exp2 * np.exp(beta1_exp2 * x + beta2_exp2 * x**2)\n",
    "                return std_poly - std_exp2\n",
    "\n",
    "            # Valores iniciales para buscar las raíces\n",
    "            valores_iniciales_2g = [-0.05, 0.05]  # Suponiendo dos intersecciones\n",
    "\n",
    "            # Resolver las raíces\n",
    "            intersecciones_2g = [fsolve(interseccion, x0)[0] for x0 in valores_iniciales_2g]\n",
    "            # Calcular las desviaciones estándar en las intersecciones\n",
    "            resultados_2g = [(x, alpha_poly + beta_1_poly * x + beta_2_poly * x**2) for x in intersecciones_2g]\n",
    "\n",
    "            # Mostrar los resultados\n",
    "            Intersección_2g = {}\n",
    "            for i, (x, y) in enumerate(resultados_2g):\n",
    "                    Intersección_2g = {'Average': f\"{x:.4f}\", 'Risk': f\"{y:.4f}\"}\n",
    "            # Crear un diccionario con las intersecciones\n",
    "            intersecciones_dict2g = {\n",
    "                 'Average': [x for x, y in resultados_2g],\n",
    "                 'Risk': [y for x, y in resultados_2g]\n",
    "                }\n",
    "            #Mostrar resultados\n",
    "            return intersecciones_dict2g\n",
    "        except ValueError as e:\n",
    "                return \"Error en la ejecución de la función\" + str(e)\n",
    "    def Model_log(stock):\n",
    "\n",
    "        try:\n",
    "            #Modelo 3\n",
    "            #Convertir a logaritmos los datos de std\n",
    "            datos['log_std'] = np.log(datos['std'])\n",
    "            datos['log_Average'] = np.log(datos['Average'].replace(0, np.nan).dropna())\n",
    "            # --- MODELO EXPONENCIAL CON LOGARITMOS ---\n",
    "\n",
    "            # Ajustar el modelo exponencial transformado con logaritmos\n",
    "            X_exp_log = sm.add_constant(datos['Average'])  # Log(σ) = Log(α) + β * Average\n",
    "            modelo_exp_log = sm.OLS(datos['log_std'], X_exp_log).fit()\n",
    "\n",
    "            # Coeficientes del modelo exponencial con logaritmos\n",
    "            beta_exp_log = modelo_exp_log.params[1]\n",
    "\n",
    "            # Predicciones del modelo exponencial con logaritmos\n",
    "            datos['log_std_pred_exp'] = modelo_exp_log.params[0] + beta_exp_log * datos['Average']\n",
    "\n",
    "            # Generar valores de x\n",
    "            x_vals = np.linspace(datos['Average'].min(), datos['Average'].max(), 500)\n",
    "\n",
    "            # Calcular valores de y para el modelo exponencial con logaritmos\n",
    "            log_std_pred_exp = modelo_exp_log.params[0] + beta_exp_log * x_vals\n",
    "            std_pred_exp = np.exp(log_std_pred_exp)  # Transformación inversa para obtener valores positivos\n",
    "\n",
    "            # Filtrar valores de x y y que no superen el rango de 0.025 y sean positivos\n",
    "            rango_mask_exp_log = (std_pred_exp > 0) & (std_pred_exp <= 0.0455)\n",
    "\n",
    "            # Crear diccionario con los datos filtrados\n",
    "            datos_filtrados = {\n",
    "                'Average': x_vals[rango_mask_exp_log],\n",
    "                'Risk': std_pred_exp[rango_mask_exp_log]\n",
    "                }\n",
    "\n",
    "                # Convertir a DataFrame\n",
    "            df_filtrado = pd.DataFrame(datos_filtrados)\n",
    "\n",
    "                # Calcular máximos y mínimos, acotación de la ecuación.\n",
    "            max_average = df_filtrado['Average'].max()\n",
    "            min_average = df_filtrado['Average'].min()\n",
    "            max_risk = df_filtrado['Risk'].max()\n",
    "            min_risk = df_filtrado['Risk'].min()\n",
    "\n",
    "            # Mostrar resultados\n",
    "            # Crear diccionario con los resultados\n",
    "            resultados_log = {\n",
    "                'Average': [max_average,min_average],\n",
    "                'Risk': [max_risk, min_risk]\n",
    "                }\n",
    "            return resultados_log\n",
    "        except ValueError as e:\n",
    "            return \"Error en la ejecución del modelo: \" + str(e)\n",
    "    # Comparar los modelos y mostrar el mejor resultado\n",
    "    def compare_models():\n",
    "        try:\n",
    "            # Ejecutar los modelos y capturar sus resultados\n",
    "            print(\"Ejecutando Model_Po_Ex...\")\n",
    "            print(\"\\nEjecutando Model_Po_Ex_2...\")\n",
    "            print(\"\\nEjecutando Model_log...\")\n",
    "            print(\"Generando resultados...\")\n",
    "\n",
    "            #Ver los resultados de los modelos ejecutados\n",
    "            resultados_modelo_1 = Model_Po_Ex(stock)\n",
    "            resultados_modelo_2 = Model_Po_Ex_2(stock)\n",
    "            resultados_modelo_3 = Model_log(stock)\n",
    "\n",
    "            #Convertir los modelos ejecutados en dataframe para procesarlos\n",
    "            modelo_1 = pd.DataFrame(resultados_modelo_1)\n",
    "            modelo_2 = pd.DataFrame(resultados_modelo_2)\n",
    "            modelo_3 = pd.DataFrame(resultados_modelo_3)\n",
    "\n",
    "           #Clasificar y especificar los valores de los 3 dataframe\n",
    "           #Clasificación de variable del modelo 1\n",
    "            return_op_model_1 = modelo_1\n",
    "\n",
    "            #datax1_return_model_1_Av = return_op_model_1.iloc[0,0] #X1 Average de modelo 1 (X1-1)\n",
    "            #datax2_return_model_1_Av = return_op_model_1.iloc[1,0] #X2 Average de modelo 1 (X2-1)\n",
    "            #datay1_return_model_1_Risk = return_op_model_1.iloc[0,1] #Y1 Risk de modelo 1 (Y1-1)\n",
    "            #datay2_return_model_1_Risk = return_op_model_1.iloc[1,1] #Y2 Risk de modelo 1 (Y2-1)\n",
    "\n",
    "            #Clasificación de variable del modelo 2\n",
    "            return_op_model_2 = modelo_2\n",
    "\n",
    "            #datax1_return_model_2_Av = return_op_model_2.iloc[0,0] #X1 Average de modelo 2 (X1-2)\n",
    "            #datax2_return_model_2_Av = return_op_model_2.iloc[1,0] #X2 Average de modelo 2 (X2-2)\n",
    "            #datay1_return_model_2_Risk = return_op_model_2.iloc[0,1] #Y1 Risk de modelo 2 (Y1-2)\n",
    "            #datay2_return_model_2_Risk = return_op_model_2.iloc[1,1] #Y2 Risk de modelo 2 (Y2-2)\n",
    "\n",
    "            #Clasificación de variable del modelo 3       \n",
    "            return_op_model_3 = modelo_3\n",
    "\n",
    "            #datax1_return_model_3_Av = return_op_model_3.iloc[0,0] #X1 Average de modelo 3 (X1-3)\n",
    "            #datax2_return_model_3_Av = return_op_model_3.iloc[1,0] #X2 Average de modelo 3 (X2-3)\n",
    "            #datay1_return_model_3_Risk = return_op_model_3.iloc[0,1] #Y1 Average de modelo 3 (Y1-3)\n",
    "            #datay2_return_model_3_Risk = return_op_model_3.iloc[1,1] #Y2 Average de modelo 3 (Y2-3)\n",
    "\n",
    "\n",
    "            #Clasificación de comparación de datos\n",
    "\n",
    "            # X1-1 > X2-1\n",
    "            # X1-1 < X2-1\n",
    "            def CC_Data_1 (return_op_model_1):\n",
    "                if return_op_model_1.iloc[0,0] > return_op_model_1.iloc[1,0]:\n",
    "                    BM1_1 = return_op_model_1.iloc[0,0]\n",
    "                    return BM1_1\n",
    "                elif return_op_model_1.iloc[0,0] < return_op_model_1.iloc[1,0]:\n",
    "                    BM2_1 = return_op_model_1.iloc[1,0]\n",
    "                    return BM2_1\n",
    "                #En caso de igualdad, poco probable\n",
    "                else:\n",
    "                    return (BM1_1 or BM2_1)\n",
    "                \n",
    "            #X1-2 > X2-2\n",
    "            #X1-2 < x2-2\n",
    "            def CC_Data_2(return_op_model_2):\n",
    "                if return_op_model_2.iloc[0,0] > return_op_model_2.iloc[1,0]:\n",
    "                    BM1_2 = return_op_model_2.iloc[0,0]\n",
    "                    return BM1_2\n",
    "                elif return_op_model_2.iloc[0,0] < return_op_model_2.iloc[1,0]:\n",
    "                    BM2_2 = return_op_model_2.iloc[1,0]\n",
    "                    return BM2_2\n",
    "                #En caso de igualdad, poco probable\n",
    "                else:\n",
    "                    return (BM1_2 or BM2_2)\n",
    "                \n",
    "            #X1-3 > X2-3\n",
    "            #X1-3 < x2-3\n",
    "            def CC_Data_3(return_op_model_3):\n",
    "                if return_op_model_3.iloc[0,0] > return_op_model_3.iloc[1,0]:\n",
    "                    BM1_3 = return_op_model_3.iloc[0,0]\n",
    "                    return BM1_3\n",
    "                elif return_op_model_3.iloc[0,0] < return_op_model_3.iloc[1,0]:\n",
    "                    BM2_3 = return_op_model_3.iloc[1,0]\n",
    "                    return BM2_3\n",
    "                #En caso de igualdad, poco probable\n",
    "                else:\n",
    "                    return (BM1_3 or BM2_3)\n",
    "                \n",
    "            #De los resultados de las anteriores funciones, se hace el ultimo proceso para sacar el mejor rendimiento\n",
    "            def CC_Data():\n",
    "                #Primera comparación\n",
    "                def FCC_Data():\n",
    "                    if CC_Data_1(return_op_model_1) > CC_Data_2(return_op_model_2):\n",
    "                        BFCM1 = CC_Data_1(return_op_model_1)\n",
    "                        return BFCM1\n",
    "                    elif CC_Data_1(return_op_model_1) < CC_Data_2(return_op_model_2):\n",
    "                        BFCM2 = CC_Data_2(return_op_model_2)\n",
    "                        return BFCM2\n",
    "                    #En caso de igualdad, poco probable\n",
    "                    else:\n",
    "                        return (BFCM1 or BFCM2)\n",
    "                def SCC_Data():\n",
    "                    if FCC_Data() > CC_Data_3(return_op_model_3):\n",
    "                        BSCM1 = FCC_Data()\n",
    "                        return BSCM1\n",
    "                    elif FCC_Data() < CC_Data_3(return_op_model_3):\n",
    "                        BSCM2 = CC_Data_3(return_op_model_3)\n",
    "                        return BSCM2 \n",
    "                    #En caso de igualdad, poco probable \n",
    "                    else:\n",
    "                        return (BSCM1 or BSCM2)\n",
    "                return SCC_Data()\n",
    "            \n",
    "            def EV_Data():\n",
    "                def EVC_Data():\n",
    "                    if CC_Data() == CC_Data_1(return_op_model_1):\n",
    "                        data_1 = CC_Data_1(return_op_model_1)\n",
    "                        BM1_1 = return_op_model_1.iloc[0,0]\n",
    "                        BM2_1 = return_op_model_1.iloc[1,0]\n",
    "                        data_1 == BM1_1 or data_1 == BM2_1\n",
    "                        return data_1\n",
    "                    elif CC_Data() == CC_Data_2(return_op_model_2):\n",
    "                        data_2 = CC_Data_2(return_op_model_2)\n",
    "                        BM1_2 = return_op_model_2.iloc[0,0]\n",
    "                        BM2_2 = return_op_model_2.iloc[1,0]\n",
    "                        data_2 == BM1_2 or data_2 == BM2_2\n",
    "                        return data_2\n",
    "                    else:\n",
    "                        data_3 = CC_Data_3(return_op_model_3)\n",
    "                        BM1_3 = return_op_model_3.iloc[0,0]\n",
    "                        BM2_3 = return_op_model_3.iloc[1,0]\n",
    "                        data_3 == BM1_3 or data_3 == BM2_3\n",
    "                        return data_3\n",
    "                    \n",
    "                def EVCR_data(): #Busqueda de la variable del mejor resultado en los modelos \n",
    "\n",
    "                    def EVCRM1_data():#Busqueda en el primer modelo\n",
    "                        if EVC_Data() == return_op_model_1.iloc[0,0]: #X1-1 (Primera variable del primer modelo)\n",
    "                            YM1_1 = return_op_model_1.iloc[0,1] #Prueba de Y1-1\n",
    "                            return YM1_1\n",
    "                        elif EVC_Data() == return_op_model_1.iloc[1,0]: #X2-1 (segundavariable del primer modelo)\n",
    "                            YM2_1 = return_op_model_1.iloc[1,1] #Prueba de Y2-1\n",
    "                            return YM2_1\n",
    "                        else: \n",
    "                            print(\"Error en encontrar el riesgo para el rendimiento asociado\")       \n",
    "                    def EVCRM2_data(): #Busqueda en el segundo modelo\n",
    "                        if EVC_Data() == return_op_model_2.iloc[0,0]: #X1-2 (Primera variable del segundo modelo)\n",
    "                            YM1_2 = return_op_model_2.iloc[0,1] #Prueba de Y1-2\n",
    "                            return YM1_2\n",
    "                        elif EVC_Data() == return_op_model_2.iloc[1,0]: #X2-2 (Segunda variable del segundo modelo)\n",
    "                            YM2_2 = return_op_model_2.iloc[1,1] #Prueba de Y2-2\n",
    "                            return YM2_2\n",
    "                        else: \n",
    "                            print(\"Error en encontrar el riesgo para el rendimiento asociado\")\n",
    "                    def EVCRM3_data(): #Busqueda de la variable del mejor resultado\n",
    "                        if EVC_Data() == return_op_model_3.iloc[0,0]: #X1-3 (Primera variable del tercer modelo)\n",
    "                            YM1_3 = return_op_model_3.iloc[0,1] #Prueba de Y1-3\n",
    "                            return YM1_3\n",
    "                        elif EVC_Data() == return_op_model_3.iloc[1,0]: #X2-3 (Segunda variable del tercer modelo)\n",
    "                            YM2_3 = return_op_model_3.iloc[1,1] #Prueba de Y2-3\n",
    "                            return YM2_3\n",
    "                        else: \n",
    "                            print(\"Error en encontrar el riesgo para el rendimiento asociado\")\n",
    "                    return EVCRM3_data()  \n",
    "                return print(\"El rendimiento asociado a la acción es la siguiete\",EVC_Data(), \"El riesgo asociado a la acción es la siguiente\",EVCR_data())\n",
    "            return EV_Data()\n",
    "        except Exception as e:\n",
    "            print(\"Error al comparar los modelos: \" + str(e))\n",
    "    return compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando Model_Po_Ex...\n",
      "\n",
      "Ejecutando Model_Po_Ex_2...\n",
      "\n",
      "Ejecutando Model_log...\n",
      "Generando resultados...\n",
      "El rendimiento asociado a la acción es la siguiete 0.33597129403742687 El riesgo asociado a la acción es la siguiente 0.01727223752991402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\retir\\AppData\\Local\\Temp\\ipykernel_3644\\2664728773.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  alpha_poly = modelo_poly.params[0]\n",
      "C:\\Users\\retir\\AppData\\Local\\Temp\\ipykernel_3644\\2664728773.py:37: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  beta_1_poly = modelo_poly.params[1]\n",
      "C:\\Users\\retir\\AppData\\Local\\Temp\\ipykernel_3644\\2664728773.py:38: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  beta_2_poly = modelo_poly.params[2]\n",
      "C:\\Users\\retir\\AppData\\Local\\Temp\\ipykernel_3644\\2664728773.py:96: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  alpha_poly = modelo_poly.params[0]\n",
      "C:\\Users\\retir\\AppData\\Local\\Temp\\ipykernel_3644\\2664728773.py:97: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  beta_1_poly = modelo_poly.params[1]\n",
      "C:\\Users\\retir\\AppData\\Local\\Temp\\ipykernel_3644\\2664728773.py:98: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  beta_2_poly = modelo_poly.params[2]\n",
      "C:\\Users\\retir\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\retir\\AppData\\Local\\Temp\\ipykernel_3644\\2664728773.py:156: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  beta_exp_log = modelo_exp_log.params[1]\n",
      "C:\\Users\\retir\\AppData\\Local\\Temp\\ipykernel_3644\\2664728773.py:159: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  datos['log_std_pred_exp'] = modelo_exp_log.params[0] + beta_exp_log * datos['Average']\n",
      "C:\\Users\\retir\\AppData\\Local\\Temp\\ipykernel_3644\\2664728773.py:165: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  log_std_pred_exp = modelo_exp_log.params[0] + beta_exp_log * x_vals\n"
     ]
    }
   ],
   "source": [
    "StockAns(\"AAPL\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
